目的
最小vSphere環境で、Kubernetesの環境構築、さらにバックアップ環境を作成する。

既設のvSphere環境に最小限の影響、最小限のリソース追加で実現することを目的とする
また、loadbalancer環境を設置することで、ポートフォーワードをすることなくアクセスができ、パブリッククラウドで使っていたデプロイメントの移植性を高める。
いうまでもないが本番環境には向かない。少なくともKindやMinikubeのように、Docker in Dockerのような閉じた環境よりは便利
vSphere CSI driverを利用することによって、vSphere 6.7U3からサポートされたFCDというDiskオブジェクトの利用も体験する

---
このスクリプトで構成されるもの
コンテナ環境
作成するKubernetsは最新(2021/11)より、１つ古いバージョン。また、Docker Shimではなく、Containerdを利用（Docker Shimが非推奨なため）
  Kubernetes 1.21.06/containerd.io 1.4.11 (1ノード)
    CNI: Metallb
    CSI: Hostpath-CSI/NFS-CSI/vSphere-CSI

付随環境
　Minio オブジェクトストレージ
　NFSサーバ (NFS-CSI用）
　Docker Registryサーバ


 
----
必要なもの
 vSphere 6.7U3以上のvCenter Server１台と最低1台のESX、データストア（なんでもいいが、vSANがあるとRWXで作成できる。今回は割愛）
  最低でも4vCPU 8-16GB RAM 100GB HDDが立ち上げられるリソース

---
必要なネットワーク
　インターネット接続
以下同じセグメントでIPアドレスを用意
　Ubuntu VM用のIP address １個
　　　例 192.168.133.83/24
　Loadbalancer用のIP address 16個  (サブネット指定）
           例  192.168.133.208/28

vSphere側では、１つのポートグループしか使わないので、VLAN、DVSとかも要らない。ネットワーク要件を満たすならVM Networkだけあればいい。
上位ルータもインターネットに出れるのであれば、特に設定不要。

---


---
VMの構成
 OS: Ubuntu Server 20.04.3のVMを１つ
 VMの設定
    4vCPU以上 (vCPUをケチるとアプリの展開ができなくなる。その場合は、workerノードを足せばいいのだが。）
    8GBメモリ以上 (CPU同様。ケチるとアプリの展開ができなくなる。）
     100GB HDD 
     　Kuberntes環境 20GB、
     　残りは、MINIO、NFS-CSI領域、ローカルレポジトリ領域で利用。/diskに別のボリュームをマウントしておくと容量が拡張しやすい。
     VMの設定：DISKUUIDの設定を必ず有効にしておく。この設定がないと、ノードからボリュームをマウントできない。
---

Ubuntuのインストール
　100GB HDDをxfsにして、LVMを構築してインストール。（何も考えずにext4 LVMでも動く。）
　IPアドレスは、１ノードなのでDHCPでも構わないし、問題なく動作するが、固定IPアドレスにしておいたほうが無難
　パッケージは、OpenSSH Serverのインストール。Dockerはインストールしてはいけない。（ディストリビューション付属のDockerはコンテナ利用では難がある）

ユーザでログインをしたら、sudo -iで rootになる。パッケージをインストールするので、基本的には構築の間はずっとrootで作業を行う。
パッケージの入手
git clone https://github.com/masezou/k8s-study-vanilla

パッケージの設定変更
cd k8s-study-vanilla
vi 3-configk8s.sh
--> ファイル先頭にある IPRANGE="192.168.133.208/28"を設定変更
     このサブネットがLoadBalancerが降り出すIPレンジとなる。もちろん、このサーバど同じセグメントで、このIPを持っているホストがいないことが前提。

vi 5-csi-vsphere.sh
以下にvCenter/ESXの情報を入れる
#For vSphere CSI/Tanzu
VSPHEREUSERNAME="administrator@vsphere.local"
VSPHEREPASSWORD="PASSWORD"
VSPHERESERVER="YOUR_vCENTER_FQDN"
VSPHERESERVERIP="YOUR_vCENTE_IP"
VSPPHEREDATASTORE="YOUR_DATASTORE"

vi K3-kasten-vsphere.sh
以下にvCenter/ESXの情報を入れる
VSPHEREUSERNAME="administrator@vsphere.local"
VSPHEREPASSWORD="PASSWORD"
VSPHERESERVER="YOUR_VCENTER_FQDN"

スクリプトの実行（その１）
これでほとんどの環境が作成される。
 ./0-minio.sh ; ./1-tools.sh ; ./2-buildk8s-lnx.sh ; ./3-configk8s.sh ; ./4-csi-storage.sh
画面と睨めっこしながら、コーヒーでもすすることをおすすめする。
スクリプトが終わってプロンプトが帰ってきたら、一度ログアウトして、再度ログインをすることをおすすめする。

出来上がったかどうかの確認
Note: MACのGoogle Chromeからアクセスする場合、証明書エラーが突破できない。なので、"This is unsafe"とタイプ（空ウチ）すると画面が出てくる。

minioの確認
  mc admin info local
●  192.168.133.83:9000
   Uptime: 9 minutes
   Version: 2021-11-03T03:36:36Z
   Network: 1/1 OK
   Drives: 4/4 OK

4 drives online, 0 drives offline 
上記で4Driveと出ているのは、Immutable設定が利用できるようにしたため。実際は単なる４つのディレクトリである。

  minioのコンソール: https://<このVMのIP>:9001
    Username/Passwordともに minioadminuser 
  APIは、https://<このVMのIP>:9000で、クレデンシシャルは同じ

NFSの確認
  showmount -e
Export list for k8s-demo1:
/disk/k8s_share 127.0.0.1/8,10.0.0.0/8,172.16.0.0/12,192.168.0.0/16

    /disk/k8s_share がエクスポートされていること
    
Local Registryの確認

Dockerの入っている別の端末でPull/Pushの確認（これができなくても支障はない。。。）
docker pull ubuntu:xenial
docker tag ubuntu:xenial <このVMのIP>:5000/ubuntu
docker push <このVMのIP>:5000/ubuntu

実行例
root@k8s-demo1:~/k8s-study-vanilla# docker pull ubuntu:xenial
xenial: Pulling from library/ubuntu
58690f9b18fc: Pull complete
b51569e7c507: Pull complete
da8ef40b9eca: Pull complete
fb15d46c38dc: Pull complete
Digest: sha256:0f71fa8d4d2d4292c3c617fda2b36f6dabe5c8b6e34c3dc5b0d17d4e704bd39c
Status: Downloaded newer image for ubuntu:xenial
docker.io/library/ubuntu:xenial
root@k8s-demo1:~/k8s-study-vanilla# docker tag ubuntu:xenial 192.168.133.83:5000/ubuntu
root@k8s-demo1:~/k8s-study-vanilla# docker push 192.168.133.83:5000/ubuntu
Using default tag: latest
The push refers to repository [192.168.133.83:5000/ubuntu]
1251204ef8fc: Pushed
47ef83afae74: Pushed
df54c846128d: Pushed
be96a3f634de: Pushed
latest: digest: sha256:a3785f78ab8547ae2710c89e627783cfa7ee7824d3468cae6835c9f4eae23ff7 size: 1150

kubernetes環境の確認
 kubectl get nodes
   １台だけノードがあり、よくみるとmaster/worker兼務になっている
 NAME        STATUS   ROLES                         AGE     VERSION
k8s-demo1   Ready    control-plane,master,worker   3m17s   v1.21.6
   
 kubectl get pod -A
   csi-nfs-controllerだけPendingになっているが、後は全てRunning/Completedになっているはず。

 kubectl get svc -A
NAMESPACE              NAME                                 TYPE           CLUSTER-IP       EXTERNAL-IP       PORT(S)                      AGE
default                hostpath-service                     NodePort       10.102.140.234   <none>            10000:31501/TCP              13m
default                kubernetes                           ClusterIP      10.96.0.1        <none>            443/TCP                      13m
ingress-nginx          ingress-nginx-controller             LoadBalancer   10.97.26.75      192.168.133.209   80:32047/TCP,443:32106/TCP   13m
ingress-nginx          ingress-nginx-controller-admission   ClusterIP      10.106.102.47    <none>            443/TCP                      13m
kube-system            kube-dns                             ClusterIP      10.96.0.10       <none>            53/UDP,53/TCP,9153/TCP       13m
kube-system            metrics-server                       ClusterIP      10.105.98.161    <none>            443/TCP                      13m
kubernetes-dashboard   dashboard-metrics-scraper            ClusterIP      10.109.199.14    <none>            8000/TCP                     13m
kubernetes-dashboard   dashboard-service-lb                 LoadBalancer   10.109.37.4      192.168.133.208   443:30085/TCP                13m
kubernetes-dashboard   kubernetes-dashboard                 ClusterIP      10.109.235.233   <none>            443/TCP                      13m

   Kubernetes DashboardにIPRANGEで指定した範囲内のIPアドレスが振られているはず。
   https://<このVMのIP>/
   ログインに必要なtokenは、k8s-study-vanilla/dashboard.tokenに記載されている
  kubectl get sc
  今の時点で、以下のドライバが表示されている
NAME                        PROVISIONER           RECLAIMPOLICY   VOLUMEBINDINGMODE   ALLOWVOLUMEEXPANSION   AGE
csi-hostpath-sc (default)   hostpath.csi.k8s.io   Delete          Immediate           true                   12m
nfs-csi                     nfs.csi.k8s.io        Delete          Immediate           false                  12m

  csi-hostpath-sc
    1ノードでしか利用できない、ローカルストレージドライバ。ただし、スナップショットが使える。一見便利そうだが、bitnamiとかのhelmでインストールをする場合は、volumePermissions.enabled=trueが必要になる。パーミッションの問題に遭遇しやすい。
 nfs-csi
   /disk/k8s_share/にPVCが作成される。
   NFSでPVCを作ってくれる。このドライバは、ReadWriteMany(RWX)でPVCを作れるので、AutoScaleなどのテストでも使える。スナップショットは未サポート。

PVCの動作確認は、実際にPVCが作成されて、podでマウントできることを確認することをおすすめする。（テストデプロイメントはネットに転がっているものでOK)

vSphere上で構築していないあるいは、vSphere環境に触りたくない、触れない場合は、ここで基盤作成完了。
k8s-demo1-cl-k8s-demo1_kubeconfigというファイルを手元のPCに持ってくれば、手元の端末でkubectl が扱える。

vSphere CSI Driverのインストール
./5-csi-vsphere.sh

vSphere CSI Driverのインストール確認
vCenterでのストレージポリシーの確認
vCenterで以下の確認をする。（vCenterでのポリシーは、スクリプトが勝手に作ってくれます。なので、正常であれば、ポリシーはあるはずです。）

ポリシーk8s-policyができていて、対象のデータストアが指定できていることを確認する。

ノードでの確認
vsphre-scで指定されているpolicyとvCenterで指定しているポリシー名が合致していることを確認する。
 kubectl describe sc vsphere-sc
Name:            vsphere-sc
IsDefaultClass:  Yes
Annotations:     kubectl.kubernetes.io/last-applied-configuration={"apiVersion":"storage.k8s.io/v1","kind":"StorageClass","metadata":{"annotations":{"storageclass.kubernetes.io/is-default-class":"true"},"name":"vsphere-sc"},"parameters":{"fstype":"ext4","storagepolicyname":"k8s-policy"},"provisioner":"csi.vsphere.vmware.com"}
,storageclass.kubernetes.io/is-default-class=true
Provisioner:           csi.vsphere.vmware.com
Parameters:            fstype=ext4,storagepolicyname=k8s-policy
AllowVolumeExpansion:  <unset>
MountOptions:          <none>
ReclaimPolicy:         Delete
VolumeBindingMode:     Immediate
Events:                <none>
ls -l /dev/disk/by-id/wwn-*
ここに少なくともsdaが表示されている必要がある。表示されていない場合は、DISKUUIDの設定の確認を。多分設定忘れている。

ちなみにvsphere-scでPVCをつくると
kubectl get pvc -A
NAMESPACE   NAME            STATUS   VOLUME                                     CAPACITY   ACCESS MODES   STORAGECLASS   AGE
test3       task-pv-claim   Bound    pvc-562b073c-4d5f-45b0-b076-a2a2faed7887   1Gi        RWO            vsphere-sc     28s

PowerCLIでは、対応するvDISKが表示される。
get-vdisk  | Format-Table -AutoSize -Wrap

Name                                     Disk Type CapacityGB                                                      Filename
----                                     --------- ----------                                                      --------
pvc-562b073c-4d5f-45b0-b076-a2a2faed7887 Flat      1.000      [qnap2_iscsi] fcd/_008e/f44cb308a27f4d01ae8e59012a5e578e.vmdk



これでvSphere CSIドライバの導入が完了した。今サポートしているStorageClassは、
kubectl get sc
NAME                   PROVISIONER              RECLAIMPOLICY   VOLUMEBINDINGMODE   ALLOWVOLUMEEXPANSION   AGE
csi-hostpath-sc        hostpath.csi.k8s.io      Delete          Immediate           true                   48m
nfs-csi                nfs.csi.k8s.io           Delete          Immediate           false                  47m
vsphere-sc (default)   csi.vsphere.vmware.com   Delete          Immediate           false                  24m
となる。

デモアプリの使い方。
vi P-wordpress.sh
以下でnamespaceと作成するSCを指定できる。
NAMESPACE=wordpress-sample
SC=vsphere-sc
変更したら、
./P-wordpress.sh

また、SC=csi-hostpath-sc とした場合の考慮は不要で、何も考えずに実行ができる。
スクリプトの最後にWordpressのURLが表示される。見逃したら
kubectl -n <NAMESPACE> get svc
でIPアドレスがわかる。


Kastenのインストールの仕方
./K0-kasten-tools.sh ; ./K1-kasten.sh
K0-kasten-tools.shで、コマンドとkubestrが自動でインストールされる
K1-kasten.shで、Kastenで必要となるスナップショットの注釈をした上で、Kastenをインストールをし、NFS-CSIがあればバックアップ用のストレージとしてNFS PVCを作成してくれる
  CSI Provisioner doesn't have VolumeSnapshotClass  -  Error
  と表示されるが、NFS-CSIはスナップショットが使えないので無視していい。
kasten-ioのPodが全てRunningになったら、
kubectl -n kasten-io get svc | grep gateway-ext
ここで表示されたIPアドレスを開く
http://<EXTERNAL-IP>/k10/
ログイン画面が開くので
k10-k10.tokenに記載されているトークンを入力する。
cat k10-k10.token

ちなみに、K1-Kasten.shは、オンラインインストールだが、以下に書かれているAir Gapインストールも利用できる。
https://docs.kasten.io/latest/install/offline.html#air-gapped-k10-installation
注意点は、repo.example.comと書かれているところを<このVMのIPアドレス>:5000として実行すること。

  
ダッシュボードで設定してもいいのだが、以下で、バックアップストレージのminioとNFSの保存先が自動設定できる。
K2-kasten-storage.sh
vSphere CSIドライバを使う場合は、同様に、以下でvCenterの設定が自動設定できる。
K3-kasten-vsphere.sh

